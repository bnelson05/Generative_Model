{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM69r2HHMM38Q3NgBD1D2+j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bnelson05/Generative_Model/blob/main/GenerativeModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part A: Data Loading and Splitting\n",
        "\n"
      ],
      "metadata": {
        "id": "5mFn9zJlcrM2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the tiny_shakespeare Dataset\n",
        "Use the Hugging Face datasets library’s load_dataset function with \"tiny_shakespeare\" as the argument.\n",
        "\n",
        "Inspect the result to confirm you have splits named “train,” “validation,” and “test.”\n",
        "\n",
        "Notice that each of these splits contains only 1 example (a single long string)."
      ],
      "metadata": {
        "id": "n_VVPi93Ybmk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "pdAsyi-6-YZp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c716b4c8-b1d3-48f8-b349-1a9666ee0aa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split type: train\n",
            "Example (first 100 chars): First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n",
            "Split type: validation\n",
            "Example (first 100 chars): ?\n",
            "\n",
            "GREMIO:\n",
            "Good morrow, neighbour Baptista.\n",
            "\n",
            "BAPTISTA:\n",
            "Good morrow, neighbour Gremio.\n",
            "God save you, \n",
            "Split type: test\n",
            "Example (first 100 chars): rance ta'en\n",
            "As shall with either part's agreement stand?\n",
            "\n",
            "BAPTISTA:\n",
            "Not in my house, Lucentio; for, \n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "tiny_shakespeare_ds = load_dataset(\"tiny_shakespeare\")\n",
        "\n",
        "for split in tiny_shakespeare_ds:\n",
        "  print(f\"Split type: {split}\")\n",
        "  example = tiny_shakespeare_ds[split][0]['text']\n",
        "  print(f\"Example (first 100 chars): {example[:100]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Examine the Data\n",
        "Retrieve the string from the \"train\" split. (For example, you’ll see a dictionary with a key like \"text\"—that’s your single item.)\n",
        "\n",
        "Print out a small snippet (e.g., the first few hundred characters) to see how it looks. Notice it’s multiple lines of Shakespeare text, separated by \\n."
      ],
      "metadata": {
        "id": "34A7KglDYlRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_string_segment = tiny_shakespeare_ds[\"train\"][0][\"text\"]\n",
        "print(train_string_segment[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBpMI2HMYqWo",
        "outputId": "d075b4e9-896c-4ea6-d208-214ceda7f830"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert the Single Example into Multiple Lines\n",
        "You’ll need to split the long string using the newline character (\"\\n\").\n",
        "Remove any lines that are completely empty or just whitespace.\n",
        "\n",
        "Finally, you’ll have a list of lines—each line is a small piece of Shakespeare text."
      ],
      "metadata": {
        "id": "uEac5iojYq-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split_by_lines = train_string_segment.split(\"\\n\")\n",
        "# Use .strip() function for clearing whitespaceL: https://www.w3schools.com/python/ref_string_strip.asp\n",
        "final_lines = [line for line in split_by_lines if line.strip()]\n",
        "print(final_lines[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdqVBtPEYzLY",
        "outputId": "41c94bf5-904f-401f-9d46-4207756e4d75"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['First Citizen:', 'Before we proceed any further, hear me speak.', 'All:', 'Speak, speak.', 'First Citizen:', 'You are all resolved rather to die than to famish?', 'All:', 'Resolved. resolved.', 'First Citizen:', 'First, you know Caius Marcius is chief enemy to the people.', 'All:', \"We know't, we know't.\", 'First Citizen:', \"Let us kill him, and we'll have corn at our own price.\", \"Is't a verdict?\", 'All:', \"No more talking on't; let it be done: away, away!\", 'Second Citizen:', 'One word, good citizens.', 'First Citizen:']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a Dataset of Lines\n",
        "Transform that list of lines into a Hugging Face Dataset object.\n",
        "\n",
        "This will give you a dataset with many rows (one row per line), rather than a single row with a giant string."
      ],
      "metadata": {
        "id": "clFXqpOfYusg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "# Hugging Face Create a Dataset: https://huggingface.co/docs/datasets/en/create_dataset\n",
        "dataset_dict = {\"text\": final_lines}\n",
        "lines_dataset = Dataset.from_dict(dataset_dict)\n",
        "print(lines_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNFDC563YuXE",
        "outputId": "754daccf-746e-44a3-edf8-dd2f3c37a366"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['text'],\n",
            "    num_rows: 29242\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split That Dataset into Train & Validation\n",
        "Use the .train_test_split method (from the datasets library) on your newly created dataset.\n",
        "\n",
        "Choose a test size (like 0.1, or 10%). The result is a DatasetDict with a “train” split and a “test” split.\n",
        "\n",
        "Name them train_data and val_data (since we’re treating the test split as validation).\n",
        "\n",
        "Print out the sizes to confirm you have a healthy number of lines in each."
      ],
      "metadata": {
        "id": "C2IAYdCNY0PU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lines_dataset_split = lines_dataset.train_test_split(test_size = 0.1)\n",
        "\n",
        "train_data = lines_dataset_split[\"train\"]\n",
        "val_data = lines_dataset_split[\"test\"]\n",
        "\n",
        "print(f\"Length of train split: {len(train_data)}\")\n",
        "print(f\"Length of test split: {len(val_data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YxmsMNEY3bP",
        "outputId": "16c35d53-89c3-4ecc-ded7-386b07e68c32"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of train split: 26317\n",
            "Length of test split: 2925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AtK_MdMMdORs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}